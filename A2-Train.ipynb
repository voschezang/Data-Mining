{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sklearn.model_selection as ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "import collections, copy, pickle\n",
    "from importlib import reload\n",
    "from dateutil.parser import parse\n",
    "import scipy.linalg, scipy.stats\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'serif'\n",
    "rcParams['font.size'] = 14\n",
    "# rcParams['text.usetex'] = True\n",
    "import seaborn as sns\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "import sklearn.ensemble\n",
    "import sklearn.svm\n",
    "import sklearn.tree\n",
    "import sklearn.linear_model\n",
    "import sklearn.neighbors\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util.plot\n",
    "import util.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(util.plot)\n",
    "reload(util.data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/encoder.pkl', 'rb') as f:\n",
    "    E = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/training_set_VU_DM_clean.csv', sep=';', nrows=10*1000)\n",
    "data_test = pd.read_csv('data/test_set_VU_DM.csv', sep=',', nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm  orig_destination_distance\n",
      "rm  comp1_rate\n",
      "rm  comp1_inv\n",
      "rm  comp1_rate_percent_diff\n",
      "rm  comp2_rate\n",
      "rm  comp2_inv\n",
      "rm  comp2_rate_percent_diff\n",
      "rm  comp3_rate\n",
      "rm  comp3_inv\n",
      "rm  comp3_rate_percent_diff\n",
      "rm  comp4_rate\n",
      "rm  comp4_inv\n",
      "rm  comp4_rate_percent_diff\n",
      "rm  comp5_rate\n",
      "rm  comp5_inv\n",
      "rm  comp5_rate_percent_diff\n",
      "rm  comp6_rate\n",
      "rm  comp6_inv\n",
      "rm  comp6_rate_percent_diff\n",
      "rm  comp7_rate\n",
      "rm  comp7_inv\n",
      "rm  comp7_rate_percent_diff\n",
      "rm  comp8_rate\n",
      "rm  comp8_inv\n",
      "rm  comp8_rate_percent_diff\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for k in data.columns:\n",
    "    if data[k].isna().sum() > 0:\n",
    "        print('rm ', k)\n",
    "        data.drop(columns=[k], inplace=True)\n",
    "\n",
    "varsUsed = list(data.columns)\n",
    "# varsUsed.remove('Unnamed')\n",
    "varsUsed.remove('position')\n",
    "varsUsed.remove('random_bool')\n",
    "len(varsUsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'srch_id': KBinsDiscretizer(encode='ordinal', n_bins=array([9]), strategy='uniform'),\n",
       " 'site_id': KBinsDiscretizer(encode='ordinal', n_bins=array([9]), strategy='uniform'),\n",
       " 'visitor_location_country_id': KBinsDiscretizer(encode='ordinal', n_bins=array([9]), strategy='uniform'),\n",
       " 'prop_country_id': KBinsDiscretizer(encode='ordinal', n_bins=array([9]), strategy='uniform'),\n",
       " 'prop_id': KBinsDiscretizer(encode='ordinal', n_bins=array([9]), strategy='uniform'),\n",
       " 'srch_destination_id': KBinsDiscretizer(encode='ordinal', n_bins=array([9]), strategy='uniform'),\n",
       " 'srch_adults_count': KBinsDiscretizer(encode='ordinal', n_bins=array([5]), strategy='uniform'),\n",
       " 'srch_children_count': KBinsDiscretizer(encode='ordinal', n_bins=array([3]), strategy='uniform'),\n",
       " 'srch_room_count': KBinsDiscretizer(encode='ordinal', n_bins=array([2]), strategy='uniform'),\n",
       " 'position': KBinsDiscretizer(encode='ordinal', n_bins=array([38]), strategy='uniform'),\n",
       " 'srch_length_of_stay': KBinsDiscretizer(encode='ordinal', n_bins=array([7]), strategy='uniform'),\n",
       " 'srch_booking_window': KBinsDiscretizer(encode='ordinal', n_bins=array([28]), strategy='uniform'),\n",
       " 'prop_log_historical_price': KBinsDiscretizer(encode='ordinal', n_bins=array([3]), strategy='quantile')}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E.discretizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO encode missing data, i.e. the hotels with no clicks\n",
    "\n",
    "# note that even though the training score is an integer,\n",
    "# the predicted score is a float. The remainder terms contain information about confidence.\n",
    "\n",
    "y_labels = ['click_bool', 'booking_bool', 'gross_bookings_usd', 'score']\n",
    "y = data['score']\n",
    "x = data[varsUsed].drop(columns=y_labels)\n",
    "# x.shape, y.shape\n",
    "# x_train, x_test, y_train, y_test = ms.train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "# pd.DataFrame.drop()\n",
    "xy_train, xy_test = ms.train_test_split(data, random_state=42, test_size=0.3)\n",
    "y = 'score'\n",
    "y_train = xy_train[y].values\n",
    "y_test = xy_test[y].values\n",
    "x_train = xy_train.drop(columns=[y]).values\n",
    "x_test = xy_test.drop(columns=[y]).values\n",
    "\n",
    "# y_train = y_train[:,np.newaxis]\n",
    "# y_test = y_test[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model_func, x_train, y_train, k=None, results=None, v=0):\n",
    "    # Train for 5 folds, returing ROC AUC. You can also try 'accuracy' as a scorer\n",
    "    n_folds = 5\n",
    "    scores_acc = cross_val_score(model_func, x_train, y_train, cv=n_folds) #  scoring='accuracy' roc_auc accuracy\n",
    "#     scores_roc = cross_val_score(model_func, x_train, y_train, cv=n_folds, scoring='roc_auc') # roc_auc accuracy\n",
    "    if results is not None:\n",
    "        results[k] = scores_acc\n",
    "    if v:\n",
    "        print('scores per fold ', scores_acc)\n",
    "        print('  mean score    ', np.mean(scores_acc))\n",
    "        print('  standard dev. ', np.std(scores_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBoost 2\n",
      "GBoost 4\n",
      "RForest 2\n",
      "RForest 4\n",
      "Logit\n",
      "SVR\n",
      "KNN 5\n",
      "Ensemble Bagging\n"
     ]
    }
   ],
   "source": [
    "models = {'GBoost 2': GradientBoostingRegressor(n_estimators=1000, learning_rate=0.001,\n",
    "                                max_depth=2, random_state=0, loss='ls'),\n",
    "          'GBoost 4': GradientBoostingRegressor(n_estimators=100, learning_rate=0.01,\n",
    "                                max_depth=4, random_state=0, loss='ls'),          \n",
    "          'RForest 2': RandomForestClassifier(n_estimators=1000, max_depth=2, random_state=0),\n",
    "          'RForest 4': RandomForestClassifier(n_estimators=1000, max_depth=4, random_state=0),\n",
    "          'Logit': sklearn.linear_model.LogisticRegression(solver='liblinear', multi_class='ovr'),\n",
    "          'SVR': sklearn.svm.SVR(kernel='linear'),\n",
    "          'KNN 5': sklearn.neighbors.KNeighborsClassifier(n_neighbors=5),\n",
    "          'Ensemble Bagging': sklearn.ensemble.BaggingClassifier(n_estimators=1000),\n",
    "         }\n",
    "\n",
    "\n",
    "# models = {\n",
    "# #           'SGD': sklearn.linear_model.SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=1000, tol=1e-3),\n",
    "# #           'SVC auto': sklearn.svm.SVC(gamma='auto'), \n",
    "#           'SVC': sklearn.svm.SVC(kernel='linear'), \n",
    "# #           'SVC polynomial': sklearn.svm.SVC(kernel='poly', gamma='auto', degree=4),    \n",
    "#           'Decision Tree':  sklearn.tree.DecisionTreeClassifier(),\n",
    "#           'KNN 5': sklearn.neighbors.KNeighborsClassifier(n_neighbors=5),\n",
    "# #           'KNN 10': sklearn.neighbors.KNeighborsClassifier(n_neighbors=10),\n",
    "#           'Ensemble Random Forest': sklearn.ensemble.RandomForestClassifier(n_estimators=100),\n",
    "# #           'Ensemble Bagging': sklearn.ensemble.BaggingClassifier(n_estimators=100)\n",
    "#          }\n",
    "\n",
    "results = {}\n",
    "for k,m in models.items():\n",
    "    print(k)\n",
    "    cross_validation(m, x_train, y_train, k, results)\n",
    "#     cross_val_score(m, x_train, y_train, cv=n_folds, v=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBoost 2 & 0.8642 & 0.0009\\\\\n",
      "GBoost 4 & 0.8655 & 0.0009\\\\\n",
      "RForest 2 & 0.9686 & 0.0056\\\\\n",
      "RForest 4 & 0.9886 & 0.0034\\\\\n",
      "Logit & 0.9772 & 0.0069\\\\\n",
      "SVR & 0.4190 & 0.2510\\\\\n",
      "KNN 5 & 0.9615 & 0.0054\\\\\n",
      "Ensemble Bagging & 1.0000 & 0.0000\\\\\n",
      "\n",
      "best acc: Ensemble Bagging 1.0\n"
     ]
    }
   ],
   "source": [
    "# print('Model & Mean Acc & Std Acc & Mean ROC & Std ROC \\\\\\\\ \\n\\\\hline')\n",
    "best_k = ''\n",
    "best_mean = 0\n",
    "for k, scores_acc in results.items():\n",
    "    if np.mean(scores_acc) > best_mean:\n",
    "        best_mean = np.mean(scores_acc)\n",
    "        best_k = k\n",
    "    print('%s & %0.4f & %0.4f\\\\\\\\' % (k, np.mean(scores_acc), np.std(scores_acc)))\n",
    "print('\\nbest acc:', best_k, round(best_mean,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBoost 2 : 0.12870701795983902\n",
      "GBoost 4 : 0.1275453693298852\n",
      "RForest 2 : 0.7466666666666667\n",
      "RForest 4 : 0.02666666666666667\n",
      "Logit : 0.10333333333333333\n",
      "SVR : 0.5285970741544384\n",
      "KNN 5 : 0.9866666666666667\n",
      "Ensemble Bagging : 0.0\n"
     ]
    }
   ],
   "source": [
    "for k, est in models.items():\n",
    "    est.fit(x_train, y_train)\n",
    "    print(k,':', mean_squared_error(y_test, est.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
