{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sklearn.model_selection as ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "import collections, copy, pickle\n",
    "from termcolor import colored\n",
    "from importlib import reload\n",
    "from dateutil.parser import parse\n",
    "import scipy.linalg, scipy.stats\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'serif'\n",
    "rcParams['font.size'] = 14\n",
    "# rcParams['text.usetex'] = True\n",
    "import seaborn as sns\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "import sklearn.ensemble\n",
    "import sklearn.svm\n",
    "import sklearn.tree\n",
    "import sklearn.linear_model\n",
    "import sklearn.neighbors\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util.plot\n",
    "import util.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(util.plot)\n",
    "reload(util.data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/encoder.pkl', 'rb') as f:\n",
    "    E = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/training_set_VU_DM_clean.csv', sep=';', nrows=10*1000)\n",
    "data_test = pd.read_csv('data/test_set_VU_DM.csv', sep=',', nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm  orig_destination_distance\n",
      "rm  comp1_rate\n",
      "rm  comp1_inv\n",
      "rm  comp1_rate_percent_diff\n",
      "rm  comp2_rate\n",
      "rm  comp2_inv\n",
      "rm  comp2_rate_percent_diff\n",
      "rm  comp3_rate\n",
      "rm  comp3_inv\n",
      "rm  comp3_rate_percent_diff\n",
      "rm  comp4_rate\n",
      "rm  comp4_inv\n",
      "rm  comp4_rate_percent_diff\n",
      "rm  comp5_rate\n",
      "rm  comp5_inv\n",
      "rm  comp5_rate_percent_diff\n",
      "rm  comp6_rate\n",
      "rm  comp6_inv\n",
      "rm  comp6_rate_percent_diff\n",
      "rm  comp7_rate\n",
      "rm  comp7_inv\n",
      "rm  comp7_rate_percent_diff\n",
      "rm  comp8_rate\n",
      "rm  comp8_inv\n",
      "rm  comp8_rate_percent_diff\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for k in data.columns:\n",
    "    if data[k].isna().sum() > 0:\n",
    "        print('rm ', k)\n",
    "        data.drop(columns=[k], inplace=True)\n",
    "\n",
    "varsUsed = list(data.columns)\n",
    "# varsUsed.remove('Unnamed')\n",
    "varsUsed.remove('position')\n",
    "varsUsed.remove('random_bool')\n",
    "len(varsUsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'srch_id': KBinsDiscretizer(encode='ordinal', n_bins=array([9]), strategy='uniform'),\n",
       " 'site_id': KBinsDiscretizer(encode='ordinal', n_bins=array([9]), strategy='uniform'),\n",
       " 'visitor_location_country_id': KBinsDiscretizer(encode='ordinal', n_bins=array([9]), strategy='uniform'),\n",
       " 'prop_country_id': KBinsDiscretizer(encode='ordinal', n_bins=array([9]), strategy='uniform'),\n",
       " 'prop_id': KBinsDiscretizer(encode='ordinal', n_bins=array([9]), strategy='uniform'),\n",
       " 'srch_destination_id': KBinsDiscretizer(encode='ordinal', n_bins=array([9]), strategy='uniform'),\n",
       " 'srch_adults_count': KBinsDiscretizer(encode='ordinal', n_bins=array([5]), strategy='uniform'),\n",
       " 'srch_children_count': KBinsDiscretizer(encode='ordinal', n_bins=array([3]), strategy='uniform'),\n",
       " 'srch_room_count': KBinsDiscretizer(encode='ordinal', n_bins=array([2]), strategy='uniform'),\n",
       " 'position': KBinsDiscretizer(encode='ordinal', n_bins=array([38]), strategy='uniform'),\n",
       " 'srch_length_of_stay': KBinsDiscretizer(encode='ordinal', n_bins=array([7]), strategy='uniform'),\n",
       " 'srch_booking_window': KBinsDiscretizer(encode='ordinal', n_bins=array([28]), strategy='uniform'),\n",
       " 'prop_log_historical_price': KBinsDiscretizer(encode='ordinal', n_bins=array([3]), strategy='quantile')}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E.discretizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO encode missing data, i.e. the hotels with no clicks\n",
    "\n",
    "# note that even though the training score is an integer,\n",
    "# the predicted score is a float. The remainder terms contain information about confidence.\n",
    "\n",
    "y_labels = ['click_bool', 'booking_bool', 'gross_bookings_usd', 'score']\n",
    "y = data['score']\n",
    "x = data[varsUsed].drop(columns=y_labels)\n",
    "# x.shape, y.shape\n",
    "# x_train, x_test, y_train, y_test = ms.train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "# pd.DataFrame.drop()\n",
    "xy_train, xy_test = ms.train_test_split(data, random_state=42, test_size=0.3)\n",
    "y = 'score'\n",
    "y_train = xy_train[y].values\n",
    "y_test = xy_test[y].values\n",
    "x_train = xy_train.drop(columns=[y]).values\n",
    "x_test = xy_test.drop(columns=[y]).values\n",
    "\n",
    "# y_train = y_train[:,np.newaxis]\n",
    "# y_test = y_test[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model_func, x_train, y_train, k=None, results=None, v=0):\n",
    "    # Train for 5 folds, returing ROC AUC. You can also try 'accuracy' as a scorer\n",
    "    n_folds = 5\n",
    "    # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    scoring1 = 'explained_variance' # explained_variance neg_mean_squared_error r2\n",
    "    scores_1 = cross_val_score(model_func, x_train, y_train, cv=n_folds, scoring=scoring1)\n",
    "    scoring2 = 'r2' # explained_variance neg_mean_squared_error r2\n",
    "    scores_2 = cross_val_score(model_func, x_train, y_train, cv=n_folds, scoring=scoring2)\n",
    "    \n",
    "    if results is not None:\n",
    "        results[k] = (scores_1, scores_2)\n",
    "    if v:\n",
    "        print('scores per fold ', scores_acc)\n",
    "        print('  mean score    ', np.mean(scores_acc))\n",
    "        print('  standard dev. ', np.std(scores_acc))\n",
    "    return (scoring1, scoring2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBoost 2\n",
      "GBoost 4\n",
      "RForest 2\n",
      "RForest 4\n",
      "Logit\n",
      "SVR\n",
      "KNN 5\n",
      "Ensemble Bagging\n",
      "\n",
      "scoring: explained_variance r2\n"
     ]
    }
   ],
   "source": [
    "kwargs = {'random_state': 123}\n",
    "models = {'GBoost 2': GradientBoostingRegressor(n_estimators=1000, learning_rate=0.001,\n",
    "                                max_depth=2, loss='ls', **kwargs),\n",
    "          'GBoost 4': GradientBoostingRegressor(n_estimators=100, learning_rate=0.01,\n",
    "                                max_depth=4, loss='ls', **kwargs),\n",
    "          'RForest 2': RandomForestClassifier(n_estimators=1000, max_depth=2, **kwargs),\n",
    "          'RForest 4': RandomForestClassifier(n_estimators=1000, max_depth=4, **kwargs),\n",
    "          'Logit': sklearn.linear_model.LogisticRegression(solver='liblinear', multi_class='ovr', **kwargs),\n",
    "          'SVR': sklearn.svm.SVR(kernel='linear'),\n",
    "          'KNN 5': sklearn.neighbors.KNeighborsClassifier(n_neighbors=5),\n",
    "          'Ensemble Bagging': sklearn.ensemble.BaggingClassifier(n_estimators=100, **kwargs),\n",
    "         }\n",
    "\n",
    "results = {}\n",
    "for k,m in models.items():\n",
    "    print(k)\n",
    "    scoring1, scoring2 = cross_validation(m, x_train, y_train, k, results)\n",
    "#     cross_val_score(m, x_train, y_train, cv=n_folds, v=1)\n",
    "print('\\nscoring:', scoring1, scoring2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model & Mean score1 & Std score1 & Mean score2 & Std score2 \\\\ \n",
      "\\hline\n",
      "GBoost 2 & 0.8648 & 0.0000 & 0.8642 & 0.0009\\\\\n",
      "GBoost 4 & 0.8660 & 0.0000 & 0.8655 & 0.0009\\\\\n",
      "RForest 2 & 0.2587 & 0.1572 & 0.2399 & 0.1648\\\\\n",
      "RForest 4 & 0.9883 & 0.0029 & 0.9882 & 0.0030\\\\\n",
      "Logit & 0.5755 & 0.2589 & 0.5671 & 0.2653\\\\\n",
      "SVR & 0.4333 & 0.2321 & 0.4190 & 0.2510\\\\\n",
      "KNN 5 & 0.0000 & 0.0000 & -0.0317 & 0.0036\\\\\n",
      "Ensemble Bagging & 1.0000 & 0.0000 & 1.0000 & 0.0000\\\\\n",
      "\n",
      "best acc: Ensemble Bagging 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Model & Mean score1 & Std score1 & Mean score2 & Std score2 \\\\\\\\ \\n\\\\hline')\n",
    "best_k = ''\n",
    "best_mean = 0\n",
    "for k, (scores_acc, scores_2) in results.items():\n",
    "    if np.mean(scores_acc) > best_mean:\n",
    "        best_mean = np.mean(scores_acc)\n",
    "        best_k = k\n",
    "    print('%s & %0.4f & %0.4f & %0.4f & %0.4f\\\\\\\\' % (k, np.mean(scores_acc), np.std(scores_acc), np.mean(scores_2), np.std(scores_2)))\n",
    "print('\\nbest acc:', best_k, round(best_mean,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best score 2: Ensemble Bagging 1.0\n"
     ]
    }
   ],
   "source": [
    "best_k = ''\n",
    "best_mean = 0\n",
    "for k, (_, scores_2) in results.items():\n",
    "    if np.mean(scores_2) > best_mean:\n",
    "        best_mean = np.mean(scores_2)\n",
    "        best_k = k\n",
    "print('\\nbest score 2:', best_k, round(best_mean,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBoost 2 : 0.12870701795983902\n",
      "GBoost 4 : 0.1275453693298852\n",
      "RForest 2 : 0.7466666666666667\n",
      "RForest 4 : 0.02666666666666667\n",
      "Logit : 0.10333333333333333\n",
      "SVR : 0.5285970741544384\n",
      "KNN 5 : 0.9866666666666667\n",
      "Ensemble Bagging : 0.0\n"
     ]
    }
   ],
   "source": [
    "# performance on test data\n",
    "for k, est in models.items():\n",
    "    est.fit(x_train, y_train)\n",
    "    print(k,':', mean_squared_error(y_test, est.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBoost 2 : 0.1295480166794545\n",
      "GBoost 4 : 0.1283787775930833\n",
      "RForest 2 : 0.26857142857142857\n",
      "RForest 4 : 0.008571428571428572\n",
      "Logit : 0.002857142857142857\n",
      "SVR : 0.4532242436615893\n",
      "KNN 5 : 0.9885714285714285\n",
      "Ensemble Bagging : 0.0\n"
     ]
    }
   ],
   "source": [
    "# performance on training data\n",
    "for k, est in models.items():\n",
    "    est.fit(x_train, y_train)\n",
    "    print(k,':', mean_squared_error(y_train, est.predict(x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search to find best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0001, 0.0001)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0001, 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# GBoost (score: explained_variance)\n",
      "Best params (train)\n",
      "\t {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100}\n",
      "\u001b[32mmse: 0.0000\u001b[0m\n",
      "\n",
      "# Random Forest (score: explained_variance)\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "kwargs = {'random_state': 123}\n",
    "params = {}\n",
    "models = {}\n",
    "models['GBoost'] = GradientBoostingRegressor(criterion='friedman_mse', loss='ls', tol=1e-4, **kwargs)\n",
    "params['GBoost'] = {'n_estimators': [100,1000], \n",
    "                    'learning_rate': [0.1, 0.01, 0.001],\n",
    "                    'max_depth': [2,3,4]\n",
    "                   }\n",
    "models['Random Forest'] = RandomForestClassifier(criterion='gini', n_jobs=2, **kwargs)\n",
    "params['Random Forest'] = {'n_estimators': [100,1000], \n",
    "                            'max_depth': [2,3,4]\n",
    "                           }\n",
    "models['Logit'] = sklearn.linear_model.LogisticRegression(solver='sag', # liblinear, multi_class='ovr'\n",
    "                            multi_class='multinomial', tol=1e-4, n_jobs=2, **kwargs)\n",
    "params['Logit'] = {'C': [1, ]}\n",
    "models['SVR'] = sklearn.svm.SVR(gamma='scale', epsilon=0.1 ,tol=1e-3) # gamma = scale: 1 / n_features * X.var()\n",
    "params['SVR'] = {'kernel': ['rbf','linear'], 'C': [1, 10, 100]}\n",
    "\n",
    "\n",
    "scores = ['explained_variance'] # explained_variance neg_mean_squared_error r2\n",
    "\n",
    "for k, model in models.items():\n",
    "    for score in scores:\n",
    "        print(\"\\n# %s (score: %s)\" % (k, score))\n",
    "        assert k in params.keys(), 'models and params should have the same keys'\n",
    "        clf = sklearn.model_selection.GridSearchCV(model, params[k], cv=5, scoring=score)\n",
    "        clf.fit(x_train, y_train)\n",
    "        print(\"Best params (train)\")\n",
    "        print('\\t', clf.best_params_)\n",
    "        y_true, y_pred = y_test, clf.predict(x_test)\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        print(colored('mse: %0.4f' % mse, 'green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
