{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.datasets import make_friedman1\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sklearn.model_selection as ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "import collections, copy, pickle\n",
    "from termcolor import colored\n",
    "from importlib import reload\n",
    "from dateutil.parser import parse\n",
    "import scipy.linalg, scipy.stats\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'serif'\n",
    "rcParams['font.size'] = 14\n",
    "# rcParams['text.usetex'] = True\n",
    "import seaborn as sns\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD: https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD\n",
    "\n",
    "https://surprise.readthedocs.io/en/stable/model_selection.html#surprise.model_selection.search.GridSearchCV\n",
    "\n",
    "https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mlxtend.frequent_patterns import apriori\n",
    "\n",
    "from surprise import Reader, Dataset, SVD, NormalPredictor\n",
    "# from surprise import evaluate\n",
    "import surprise.model_selection\n",
    "# from surprise.model_selection import cross_validate\n",
    "# from surprise.model_selection import GridSearchCV\n",
    "# from surprise import accuracy\n",
    "\n",
    "import sklearn.ensemble\n",
    "import sklearn.svm\n",
    "import sklearn.tree\n",
    "import sklearn.linear_model\n",
    "import sklearn.neighbors\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util.plot\n",
    "import util.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(util.plot)\n",
    "reload(util.data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/encoder.pkl', 'rb') as f:\n",
    "    E = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/training_set_VU_DM_clean.csv', sep=';', nrows=1*1000)\n",
    "data_test = pd.read_csv('data/test_set_VU_DM.csv', sep=',', nrows=1000)\n",
    "# scores = pd.read_csv('data/scores_train.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm  orig_destination_distance\n",
      "rm  comp1_rate\n",
      "rm  comp1_inv\n",
      "rm  comp1_rate_percent_diff\n",
      "rm  comp2_rate\n",
      "rm  comp2_inv\n",
      "rm  comp2_rate_percent_diff\n",
      "rm  comp3_rate\n",
      "rm  comp3_inv\n",
      "rm  comp3_rate_percent_diff\n",
      "rm  comp4_rate\n",
      "rm  comp4_inv\n",
      "rm  comp4_rate_percent_diff\n",
      "rm  comp5_rate\n",
      "rm  comp5_inv\n",
      "rm  comp5_rate_percent_diff\n",
      "rm  comp6_rate\n",
      "rm  comp6_inv\n",
      "rm  comp6_rate_percent_diff\n",
      "rm  comp7_rate\n",
      "rm  comp7_inv\n",
      "rm  comp7_rate_percent_diff\n",
      "rm  comp8_rate\n",
      "rm  comp8_inv\n",
      "rm  comp8_rate_percent_diff\n",
      "rm  travel_distance\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for k in data.columns:\n",
    "    if data[k].isna().sum() > 0:\n",
    "        print('rm ', k)\n",
    "        data.drop(columns=[k], inplace=True)\n",
    "\n",
    "varsUsed = list(data.columns)\n",
    "# varsUsed.remove('Unnamed')\n",
    "varsUsed.remove('position')\n",
    "varsUsed.remove('random_bool')\n",
    "len(varsUsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'site_id': KBinsDiscretizer(encode='ordinal', n_bins=array([9]), strategy='uniform'),\n",
       " 'visitor_location_country_id': KBinsDiscretizer(encode='ordinal', n_bins=array([9]), strategy='uniform'),\n",
       " 'prop_country_id': KBinsDiscretizer(encode='ordinal', n_bins=array([9]), strategy='uniform'),\n",
       " 'srch_destination_id': KBinsDiscretizer(encode='ordinal', n_bins=array([9]), strategy='uniform'),\n",
       " 'srch_adults_count': KBinsDiscretizer(encode='ordinal', n_bins=array([9]), strategy='uniform'),\n",
       " 'srch_children_count': KBinsDiscretizer(encode='ordinal', n_bins=array([6]), strategy='uniform'),\n",
       " 'srch_room_count': KBinsDiscretizer(encode='ordinal', n_bins=array([7]), strategy='uniform'),\n",
       " 'position': KBinsDiscretizer(encode='ordinal', n_bins=array([39]), strategy='uniform'),\n",
       " 'srch_length_of_stay': KBinsDiscretizer(encode='ordinal', n_bins=array([20]), strategy='uniform'),\n",
       " 'srch_booking_window': KBinsDiscretizer(encode='ordinal', n_bins=array([260]), strategy='uniform'),\n",
       " 'prop_log_historical_price': KBinsDiscretizer(encode='ordinal', n_bins=array([3]), strategy='quantile')}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E.discretizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering (CF)\n",
    "\n",
    "Neglect user and item info, and focus on the past behaviour, i.e. the ratings of user-item pairs.\n",
    "How to predict a new value?\n",
    "\n",
    "Firstly, the user-item (user-hotel) matrix $M_{ij}$ can be normalized by subtracting the mean (row) rating of each rating of that user.\n",
    "$$ \\forall \\langle i,j\\rangle \\quad M_{ij} = \\begin{cases}\n",
    "M_{ij} - \\sum_j M_{ij} & \\text{if exists} \\\\\n",
    "0 & \\text{otherwise} \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "(as done in centerd cosine similarity)\n",
    "\n",
    "\n",
    "### 1) Encode missing data, i.e. the hotels with no clicks\n",
    "\n",
    "- KNN\n",
    "    - Impute missing values using similar records (KNN, regression)\n",
    "- Pearson correlation to measure similarity\n",
    "\n",
    "### 2) Item-based similarity\n",
    "\n",
    "#### User-user similarity\n",
    "\n",
    "When predicting the score w.r.t. a user, average over similar users\n",
    "\n",
    "- Jaccard similarity - assumes boolean fields\n",
    "$$\\text{sim}(a,b) = \\frac{| r_a \\cup r_b |}{| r_a \\cap r_b |}$$\n",
    "\n",
    "- Cosine similarity (n-dimensional)\n",
    "$$\\text{sim}(a,b) = \\cos(r_a,r_b)$$\n",
    "    - problem: penalizes missing values\n",
    "\n",
    "- Centred Cosine similarity (n-dimensional) i.e. pearson correlation\n",
    "    - Normalize ratings by subtrating the average user rating: $r_{\\mu}$\n",
    "    - $r_a = r_a - r_{\\mu}$\n",
    "    - Missing values are treated as average and critical users are taken with a grain of salt\n",
    "\n",
    "\n",
    "Then the \"average\" rating $r_{x,i}$ of a group of $k$ users (similar to user $x$) for item $i$ is:\n",
    "$r_{x,i} = \\frac1k \\sum_{j=1}^k r_{j,i}$\n",
    "\n",
    "Incorporating the similarity measure (distance function)\n",
    "$$ r_{x,i} = \\frac1{\\sum_j \\text{sim}(x,j)} \\sum_{j=1}^k \\text{sim}(x,j)\\, r_{j,i} $$\n",
    "\n",
    "\n",
    "#### Item-item similarity\n",
    "\n",
    "Intuitively, items are often more similar than people. It is often easier to predict the quantitative similarity (distance) between items than people.\n",
    "Items can even be equivalent (e.g. two hotels next to each other with the same specs), whereas people are very unlikely to be equivalent.\n",
    "\n",
    "\n",
    "The average rating $r_{x,i}$ of a group of $k$ items (similar to item $i$) for (possibly average) user $x$ is:\n",
    "$r_{x,i} = \\frac1k \\sum_{j=1}^k r_{x,j}$\n",
    "\n",
    "Incorporating a similarity measure (distance function)\n",
    "$$ r_{x,i} = \\frac1{\\sum_{j=1}^k \\text{sim}(x,j)} \\sum_{j=1}^k \\text{sim}(x,j)\\, r_{x,j} $$\n",
    "\n",
    "\n",
    "\n",
    "### 3) SVD\n",
    "\n",
    "The aforementioned approaches use dense matrices that don't scale very well. Using a _latent factor model_ the sparsity of the data can be used to our advantage. SVD works as a kind of dimensionaliy reduction (i.e. compressing the data into the most important features).\n",
    "Note that the matrix still has to be subtracted by the row-means.\n",
    "\n",
    "\n",
    "For $m$ users, $n$ items (hotels), $M: m \\times n$, $U: m\\times m$, $\\Sigma: m\\times n$, $V^T n \\times n$.\n",
    "\n",
    "$\\Sigma$ is a diagonal with singular values.\n",
    "\n",
    "$$ M = U \\Sigma V^T$$\n",
    "i.e.\n",
    "$$ M_k = U_k \\Sigma_k V_k^T$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find USV by gradient descent, ignoring the missing terms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A = scipy.sparse.csc_matrix([[1, 0, 0], [5, 0, 2], [0, -1, 0], [0, 0, 3]], dtype=float)\n",
    "# u, s, vt = scipy.sparse.linalg.svds(A, k=2) # k is the number of factors\n",
    "# A.shape, A.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sI = scipy.sparse.csc_matrix(np.diagflat(s))\n",
    "# sI = np.diagflat(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A_pred = np.matmul(u, np.matmul(sI,vt))\n",
    "# np.round(A_pred,4)\n",
    "# # u.shape, s.shape, vt.shape, sI.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratingsMatrix[user][movie] = sum(userFeature[f][user] * movieFeature[f][movie]) for f from 1 to 40\n",
    "# for k features, n users, m items\n",
    "# B: n x m x k\n",
    "# U: n x k     user preferences\n",
    "# S: k x k     or   k\n",
    "# Vt: k x m    movie aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>site_id</th>\n",
       "      <th>visitor_location_country_id</th>\n",
       "      <th>visitor_hist_starrating</th>\n",
       "      <th>visitor_hist_adr_usd</th>\n",
       "      <th>prop_country_id</th>\n",
       "      <th>prop_id</th>\n",
       "      <th>prop_starrating</th>\n",
       "      <th>prop_review_score</th>\n",
       "      <th>prop_brand_bool</th>\n",
       "      <th>...</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.098734</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>893</td>\n",
       "      <td>-0.190084</td>\n",
       "      <td>-0.300346</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.098734</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10404</td>\n",
       "      <td>0.763816</td>\n",
       "      <td>0.191146</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.098734</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21315</td>\n",
       "      <td>-0.190084</td>\n",
       "      <td>0.682638</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.098734</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27348</td>\n",
       "      <td>-1.143983</td>\n",
       "      <td>0.191146</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.098734</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29604</td>\n",
       "      <td>0.763816</td>\n",
       "      <td>-0.300346</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   srch_id  site_id  visitor_location_country_id  visitor_hist_starrating  \\\n",
       "0        1      0.0                          8.0                 0.098734   \n",
       "1        1      0.0                          8.0                 0.098734   \n",
       "2        1      0.0                          8.0                 0.098734   \n",
       "3        1      0.0                          8.0                 0.098734   \n",
       "4        1      0.0                          8.0                 0.098734   \n",
       "\n",
       "   visitor_hist_adr_usd  prop_country_id  prop_id  prop_starrating  \\\n",
       "0              0.006029              0.0      893        -0.190084   \n",
       "1              0.006029              0.0    10404         0.763816   \n",
       "2              0.006029              0.0    21315        -0.190084   \n",
       "3              0.006029              0.0    27348        -1.143983   \n",
       "4              0.006029              0.0    29604         0.763816   \n",
       "\n",
       "   prop_review_score  prop_brand_bool  ...    hour  minute  Friday  Monday  \\\n",
       "0          -0.300346                1  ...       8      32       0       0   \n",
       "1           0.191146                1  ...       8      32       0       0   \n",
       "2           0.682638                1  ...       8      32       0       0   \n",
       "3           0.191146                1  ...       8      32       0       0   \n",
       "4          -0.300346                1  ...       8      32       0       0   \n",
       "\n",
       "   Saturday  Sunday  Thursday  Tuesday  Wednesday  score  \n",
       "0         0       0         1        0          0      0  \n",
       "1         0       0         1        0          0      0  \n",
       "2         0       0         1        0          0      0  \n",
       "3         0       0         1        0          0      0  \n",
       "4         0       0         1        0          0      0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings = {'itemID': [1, 1, 1, 2, 2],\n",
    "#             'userID': [9, 32, 2, 45, 'user_foo'],\n",
    "#             'rating': [3, 2, 4, 3, 1]}\n",
    "# tuples = pd.DataFrame(ratings)\n",
    "# reader = Reader(rating_scale=(1,5))\n",
    "# data = Dataset.load_from_df(tuples, reader)\n",
    "# cross_validate(NormalPredictor(), data, cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creation of the dataframe. Column names are irrelevant.\n",
    "# ratings_dict = {'itemID': [1, 1, 1, 2, 2],\n",
    "#                 'userID': [9, 32, 2, 45, 'user_foo'],\n",
    "#                 'rating': [3, 2, 4, 3, 1]}\n",
    "# df = pd.DataFrame(ratings_dict)\n",
    "\n",
    "# # A reader is still needed but only the rating_scale param is requiered.\n",
    "# reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# # The columns must correspond to user id, item id and ratings (in that order).\n",
    "# data = Dataset.load_from_df(df[['userID', 'itemID', 'rating']], reader)\n",
    "\n",
    "# # We can now use this dataset as we please, e.g. calling cross_validate\n",
    "# cross_validate(NormalPredictor(), data, cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that even though the training score is an integer,\n",
    "# the predicted score is a float. The remainder terms contain information about confidence.\n",
    "\n",
    "y_labels = ['click_bool', 'booking_bool', 'gross_bookings_usd', 'score']\n",
    "y = data['score']\n",
    "x = data[varsUsed].drop(columns=y_labels)\n",
    "# x.shape, y.shape\n",
    "# x_train, x_test, y_train, y_test = ms.train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "# pd.DataFrame.drop()\n",
    "xy_train, xy_test = ms.train_test_split(data, random_state=42, test_size=0.3)\n",
    "y = 'score'\n",
    "y_train = xy_train[y].values\n",
    "y_test = xy_test[y].values\n",
    "x_train = xy_train.drop(columns=[y]).values\n",
    "x_test = xy_test.drop(columns=[y]).values\n",
    "\n",
    "# y_train = y_train[:,np.newaxis]\n",
    "# y_test = y_test[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def scores_df(data):\n",
    "#     # the surprise lib requires the order item-user-score\n",
    "#     scores = {'item':[], 'user': [], 'score':[]}\n",
    "#     for i in range(data.shape[0]):\n",
    "#         row = data.iloc[i]\n",
    "#         scores['user'].append(row.srch_id)\n",
    "#         scores['item'].append(row.prop_id)\n",
    "#         scores['score'].append(row.score)\n",
    "#     return pd.DataFrame(scores), scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def score_table(data):\n",
    "#     # Return a table of scores for each user-item\n",
    "#     scores = pd.DataFrame()\n",
    "#     scores['user'] = pd.Series()\n",
    "#     rows = []\n",
    "#     # for i in range(data.shape[0]):\n",
    "#     for i in range(30):\n",
    "#         user = data.iloc[i].srch_id\n",
    "#         item = data.iloc[i].prop_id\n",
    "#         score = data.iloc[i].score\n",
    "#         row = pd.DataFrame({item:[score]}, index=[user])\n",
    "#         rows.append(row)\n",
    "    \n",
    "#     scores = pd.concat(rows, axis=1, sort=True)\n",
    "#     return scores\n",
    "\n",
    "# score_table(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.srch_id.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 53), (1000, 3), (40,), (996,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = util.data.scores_df(data)\n",
    "assert data.srch_id.unique().size == scores.user.unique().size\n",
    "assert data.prop_id.unique().size == scores.item.unique().size\n",
    "data.shape, scores.shape, scores.user.unique().shape, scores.item.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check minimal occurence\n",
    "value_counts_user = scores.user.value_counts(ascending=True)\n",
    "value_counts_item = scores.user.value_counts(ascending=True)\n",
    "assert value_counts_user.iloc[0] > 2\n",
    "assert value_counts_item.iloc[0] > 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0      5\n",
       "67.0     5\n",
       "56.0     6\n",
       "78.0     7\n",
       "42.0    11\n",
       "Name: user, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_counts_user.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0      5\n",
       "67.0     5\n",
       "56.0     6\n",
       "78.0     7\n",
       "42.0    11\n",
       "Name: user, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_counts_item.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.96561715, 0.9752576 , 1.05858818, 0.96881151, 1.05051736]),\n",
       " 'test_mae': array([0.3070419 , 0.33763562, 0.36089253, 0.34174546, 0.3412316 ]),\n",
       " 'fit_time': (0.05283188819885254,\n",
       "  0.041496992111206055,\n",
       "  0.04632425308227539,\n",
       "  0.03960013389587402,\n",
       "  0.039765119552612305),\n",
       " 'test_time': (0.0013740062713623047,\n",
       "  0.004654884338378906,\n",
       "  0.0009672641754150391,\n",
       "  0.0010457038879394531,\n",
       "  0.0009419918060302734)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reader = Reader(rating_scale=(0,6))\n",
    "data_scores = Dataset.load_from_df(scores, reader)\n",
    "surprise.model_selection.cross_validate(SVD(), data_scores, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.dataset.DatasetAutoFolds at 0x1a17e880b8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO grid search to find best params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9239844826108146\n",
      "{'n_epochs': 5, 'lr_all': 0.002, 'reg_all': 0.6}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_epochs': [5, 10], 'lr_all': [0.002, 0.005],\n",
    "              'reg_all': [0.4, 0.6]}\n",
    "gs = surprise.model_selection.GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=5)\n",
    "gs.fit(data_scores)\n",
    "print(gs.best_score['rmse'])\n",
    "print(gs.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.0502\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot compute fcp on this list of prediction. Does every user have at least two predictions?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/surprise/accuracy.py\u001b[0m in \u001b[0;36mfcp\u001b[0;34m(predictions, verbose)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mfcp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnc\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mZeroDivisionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-b95f4056760e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msurprise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msurprise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfcp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/surprise/accuracy.py\u001b[0m in \u001b[0;36mfcp\u001b[0;34m(predictions, verbose)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mZeroDivisionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         raise ValueError('cannot compute fcp on this list of prediction. ' +\n\u001b[0;32m--> 138\u001b[0;31m                          'Does every user have at least two predictions?')\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot compute fcp on this list of prediction. Does every user have at least two predictions?"
     ]
    }
   ],
   "source": [
    "# model = SVD(**gs.best_params['rmse'])\n",
    "model = SVD()\n",
    "\n",
    "trainset, testset = surprise.model_selection.train_test_split(data_scores, test_size=0.3, random_state=seed)\n",
    "model.fit(trainset)\n",
    "predictions = model.test(testset)\n",
    "surprise.accuracy.rmse(predictions), surprise.accuracy.fcp(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item     68914.0\n",
       "user         1.0\n",
       "score        6.0\n",
       "Name: 12, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = scores.iloc[scores.score.idxmax()]\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 1.0        item: 68914.0    r_ui = 4.00   est = 0.18   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "uid = str(best['user'])\n",
    "iid = str(best['item'])\n",
    "pred = model.predict(uid, iid, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 1.0        item: 893.0      r_ui = 4.00   est = 0.18   {'was_impossible': False}\n",
      "user: 1.0        item: 10404.0    r_ui = 4.00   est = 0.18   {'was_impossible': False}\n",
      "user: 1.0        item: 21315.0    r_ui = 4.00   est = 0.18   {'was_impossible': False}\n",
      "user: 1.0        item: 27348.0    r_ui = 4.00   est = 0.18   {'was_impossible': False}\n",
      "user: 1.0        item: 29604.0    r_ui = 4.00   est = 0.18   {'was_impossible': False}\n",
      "user: 1.0        item: 30184.0    r_ui = 4.00   est = 0.18   {'was_impossible': False}\n",
      "user: 1.0        item: 44147.0    r_ui = 4.00   est = 0.18   {'was_impossible': False}\n",
      "user: 1.0        item: 50984.0    r_ui = 4.00   est = 0.18   {'was_impossible': False}\n",
      "user: 1.0        item: 53341.0    r_ui = 4.00   est = 0.18   {'was_impossible': False}\n",
      "user: 1.0        item: 56880.0    r_ui = 4.00   est = 0.18   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    best = scores.iloc[i]\n",
    "    uid = str(best['user'])\n",
    "    iid = str(best['item'])\n",
    "    pred = model.predict(uid, iid, r_ui=4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>user</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>893.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10404.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21315.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27348.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29604.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      item  user  score\n",
       "0    893.0   1.0    0.0\n",
       "1  10404.0   1.0    0.0\n",
       "2  21315.0   1.0    0.0\n",
       "3  27348.0   1.0    0.0\n",
       "4  29604.0   1.0    0.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item     893.0\n",
       "user       1.0\n",
       "score      0.0\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model_func, x_train, y_train, k=None, results=None, v=0):\n",
    "    # Train for 5 folds, returing ROC AUC. You can also try 'accuracy' as a scorer\n",
    "    n_folds = 5\n",
    "    # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    scoring1 = 'explained_variance' # explained_variance neg_mean_squared_error r2\n",
    "    scores_1 = cross_val_score(model_func, x_train, y_train, cv=n_folds, scoring=scoring1)\n",
    "    scoring2 = 'r2' # explained_variance neg_mean_squared_error r2\n",
    "    scores_2 = cross_val_score(model_func, x_train, y_train, cv=n_folds, scoring=scoring2)\n",
    "    \n",
    "    if results is not None:\n",
    "        results[k] = (scores_1, scores_2)\n",
    "    if v:\n",
    "        print('scores per fold ', scores_acc)\n",
    "        print('  mean score    ', np.mean(scores_acc))\n",
    "        print('  standard dev. ', np.std(scores_acc))\n",
    "    return (scoring1, scoring2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBoost 2\n",
      "GBoost 4\n",
      "RForest 2\n",
      "RForest 4\n",
      "Logit\n",
      "SVR\n",
      "KNN 5\n",
      "Ensemble Bagging\n",
      "\n",
      "scoring: explained_variance r2\n"
     ]
    }
   ],
   "source": [
    "kwargs = {'random_state': 123}\n",
    "models = {'GBoost 2': GradientBoostingRegressor(n_estimators=1000, learning_rate=0.001,\n",
    "                                max_depth=2, loss='ls', **kwargs),\n",
    "          'GBoost 4': GradientBoostingRegressor(n_estimators=100, learning_rate=0.01,\n",
    "                                max_depth=4, loss='ls', **kwargs),\n",
    "          'RForest 2': RandomForestClassifier(n_estimators=1000, max_depth=2, **kwargs),\n",
    "          'RForest 4': RandomForestClassifier(n_estimators=1000, max_depth=4, **kwargs),\n",
    "          'Logit': sklearn.linear_model.LogisticRegression(solver='liblinear', multi_class='ovr', **kwargs),\n",
    "          'SVR': sklearn.svm.SVR(kernel='linear'),\n",
    "          'KNN 5': sklearn.neighbors.KNeighborsClassifier(n_neighbors=5),\n",
    "          'Ensemble Bagging': sklearn.ensemble.BaggingClassifier(n_estimators=100, **kwargs),\n",
    "         }\n",
    "\n",
    "results = {}\n",
    "for k,m in models.items():\n",
    "    print(k)\n",
    "    scoring1, scoring2 = cross_validation(m, x_train, y_train, k, results)\n",
    "#     cross_val_score(m, x_train, y_train, cv=n_folds, v=1)\n",
    "print('\\nscoring:', scoring1, scoring2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model & Mean score1 & Std score1 & Mean score2 & Std score2 \\\\ \n",
      "\\hline\n",
      "GBoost 2 & 0.8648 & 0.0000 & 0.8642 & 0.0009\\\\\n",
      "GBoost 4 & 0.8660 & 0.0000 & 0.8655 & 0.0009\\\\\n",
      "RForest 2 & 0.4573 & 0.3548 & 0.4439 & 0.3658\\\\\n",
      "RForest 4 & 0.9883 & 0.0029 & 0.9882 & 0.0030\\\\\n",
      "Logit & 0.5755 & 0.2589 & 0.5671 & 0.2653\\\\\n",
      "SVR & 0.4333 & 0.2321 & 0.4190 & 0.2510\\\\\n",
      "KNN 5 & 0.0000 & 0.0000 & -0.0317 & 0.0036\\\\\n",
      "Ensemble Bagging & 1.0000 & 0.0000 & 1.0000 & 0.0000\\\\\n",
      "\n",
      "best acc: Ensemble Bagging 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Model & Mean score1 & Std score1 & Mean score2 & Std score2 \\\\\\\\ \\n\\\\hline')\n",
    "best_k = ''\n",
    "best_mean = 0\n",
    "for k, (scores_acc, scores_2) in results.items():\n",
    "    if np.mean(scores_acc) > best_mean:\n",
    "        best_mean = np.mean(scores_acc)\n",
    "        best_k = k\n",
    "    print('%s & %0.4f & %0.4f & %0.4f & %0.4f\\\\\\\\' % (k, np.mean(scores_acc), np.std(scores_acc), np.mean(scores_2), np.std(scores_2)))\n",
    "print('\\nbest acc:', best_k, round(best_mean,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "best score 2: Ensemble Bagging 1.0\n"
     ]
    }
   ],
   "source": [
    "best_k = ''\n",
    "best_mean = 0\n",
    "for k, (_, scores_2) in results.items():\n",
    "    if np.mean(scores_2) > best_mean:\n",
    "        best_mean = np.mean(scores_2)\n",
    "        best_k = k\n",
    "print('\\nbest score 2:', best_k, round(best_mean,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBoost 2 : 0.12870701795983902\n",
      "GBoost 4 : 0.1275453693298852\n",
      "RForest 2 : 0.26666666666666666\n",
      "RForest 4 : 0.02666666666666667\n",
      "Logit : 0.10333333333333333\n",
      "SVR : 0.5285970741544384\n",
      "KNN 5 : 0.9866666666666667\n",
      "Ensemble Bagging : 0.0\n"
     ]
    }
   ],
   "source": [
    "# performance on test data\n",
    "for k, est in models.items():\n",
    "    est.fit(x_train, y_train)\n",
    "    print(k,':', mean_squared_error(y_test, est.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBoost 2 : 0.1295480166794545\n",
      "GBoost 4 : 0.1283787775930833\n",
      "RForest 2 : 0.11428571428571428\n",
      "RForest 4 : 0.008571428571428572\n",
      "Logit : 0.002857142857142857\n",
      "SVR : 0.4532242436615893\n",
      "KNN 5 : 0.9885714285714285\n",
      "Ensemble Bagging : 0.0\n"
     ]
    }
   ],
   "source": [
    "# performance on training data\n",
    "for k, est in models.items():\n",
    "    est.fit(x_train, y_train)\n",
    "    print(k,':', mean_squared_error(y_train, est.predict(x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search to find best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0001, 0.0001)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.0001, 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# GBoost (score: explained_variance)\n",
      "Best params (train)\n",
      "\t {'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100}\n",
      "\u001b[32mmse: 0.0000\u001b[0m\n",
      "\n",
      "# Random Forest (score: explained_variance)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mark/miniconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params (train)\n",
      "\t {'max_depth': 3, 'n_estimators': 100}\n",
      "\u001b[32mmse: 0.0267\u001b[0m\n",
      "\n",
      "# Logit (score: explained_variance)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mark/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params (train)\n",
      "\t {'C': 1}\n",
      "\u001b[32mmse: 0.9867\u001b[0m\n",
      "\n",
      "# SVR (score: explained_variance)\n",
      "Best params (train)\n",
      "\t {'C': 1, 'kernel': 'linear'}\n",
      "\u001b[32mmse: 0.5286\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py\n",
    "kwargs = {'random_state': 123}\n",
    "params = {}\n",
    "models = {}\n",
    "models['GBoost'] = GradientBoostingRegressor(criterion='friedman_mse', loss='ls', tol=1e-4, **kwargs)\n",
    "params['GBoost'] = {'n_estimators': [100,1000], \n",
    "                    'learning_rate': [0.1, 0.01, 0.001],\n",
    "                    'max_depth': [2,3,4]\n",
    "                   }\n",
    "models['Random Forest'] = RandomForestClassifier(criterion='gini', n_jobs=2, **kwargs)\n",
    "params['Random Forest'] = {'n_estimators': [100,1000], \n",
    "                            'max_depth': [2,3,4]\n",
    "                           }\n",
    "models['Logit'] = sklearn.linear_model.LogisticRegression(solver='sag', # liblinear, multi_class='ovr'\n",
    "                            multi_class='multinomial', tol=1e-4, n_jobs=2, **kwargs)\n",
    "params['Logit'] = {'C': [1, ]}\n",
    "models['SVR'] = sklearn.svm.SVR(gamma='scale', epsilon=0.1 ,tol=1e-3) # gamma = scale: 1 / n_features * X.var()\n",
    "params['SVR'] = {'kernel': ['rbf','linear'], 'C': [1, 10, 100]}\n",
    "\n",
    "\n",
    "scores = ['explained_variance'] # explained_variance neg_mean_squared_error r2\n",
    "\n",
    "for k, model in models.items():\n",
    "    for score in scores:\n",
    "        print(\"\\n# %s (score: %s)\" % (k, score))\n",
    "        assert k in params.keys(), 'models and params should have the same keys'\n",
    "        clf = sklearn.model_selection.GridSearchCV(model, params[k], cv=5, scoring=score)\n",
    "        clf.fit(x_train, y_train)\n",
    "        print(\"Best params (train)\")\n",
    "        print('\\t', clf.best_params_)\n",
    "        y_true, y_pred = y_test, clf.predict(x_test)\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        print(colored('mse: %0.4f' % mse, 'green'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
