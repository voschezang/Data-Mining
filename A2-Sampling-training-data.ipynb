{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "import collections, copy, pickle\n",
    "from termcolor import colored\n",
    "from importlib import reload\n",
    "import gc\n",
    "from dateutil.parser import parse\n",
    "import scipy.linalg, scipy.stats\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'serif'\n",
    "rcParams['font.size'] = 14\n",
    "# rcParams['text.usetex'] = True\n",
    "import seaborn as sns\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.ensemble\n",
    "import sklearn.svm\n",
    "import sklearn.tree\n",
    "import sklearn.linear_model\n",
    "import sklearn.neighbors\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider the training dataset\n",
    "# Split the data up in n subsets, based on `search_id` to prevent occurence of a `search_id` in multiple sets\n",
    "# Resample each subset, now based on classes: select 1/3 booking, 1/3 click (but no booking), 1/3 none\n",
    "#     The resampling is used the preserve the class sizes\n",
    "# Use crossvalidation on the n sets to select hyperparams\n",
    "# Finally train model on full training dataset and make a prediction of the (unseen) test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/training_set_VU_DM_clean.csv', sep=';', nrows=2*1000)\n",
    "data_test = pd.read_csv('data/test_set_VU_DM_clean.csv', sep=';', nrows=1*1000)\n",
    "# scores = pd.read_csv('data/scores_train.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['position'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm  0.9815 comp1_rate\n",
      "rm  0.98 comp1_inv\n",
      "rm  0.984 comp1_rate_percent_diff\n",
      "rm  0.59 comp2_rate\n",
      "rm  0.5705 comp2_inv\n",
      "rm  0.8935 comp2_rate_percent_diff\n",
      "rm  0.6495 comp3_rate\n",
      "rm  0.6335 comp3_inv\n",
      "rm  0.9185 comp3_rate_percent_diff\n",
      "rm  0.94 comp4_rate\n",
      "rm  0.9315 comp4_inv\n",
      "rm  0.9785 comp4_rate_percent_diff\n",
      "rm  0.5105 comp5_rate\n",
      "rm  0.4855 comp5_inv\n",
      "rm  0.817 comp5_rate_percent_diff\n",
      "rm  0.9235 comp6_rate\n",
      "rm  0.9175 comp6_inv\n",
      "rm  0.9655 comp6_rate_percent_diff\n",
      "rm  0.9075 comp7_rate\n",
      "rm  0.8915 comp7_inv\n",
      "rm  0.96 comp7_rate_percent_diff\n",
      "rm  0.5755 comp8_rate\n",
      "rm  0.556 comp8_inv\n",
      "rm  0.876 comp8_rate_percent_diff\n"
     ]
    }
   ],
   "source": [
    "for k in data.columns:\n",
    "    if data[k].isna().sum() > 0:\n",
    "        print('rm ', data[k].isna().sum() / data.shape[0], k)\n",
    "        data.drop(columns=[k], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 800,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = sklearn.utils.shuffle(data.srch_id.unique(), random_state=123)\n",
    "# ids = data.srch_id.unique()\n",
    "N = ids.size\n",
    "N # total number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['click_bool', 'booking_bool', 'score']"
      ]
     },
     "execution_count": 797,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labels = [ k for k in data.columns if k not in data_test.columns ]\n",
    "y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 5)"
      ]
     },
     "execution_count": 801,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cv_folds = 5\n",
    "ids_selections = np.array_split(ids, n_cv_folds)\n",
    "# split data based on id folds\n",
    "data_splits = [ data.loc[data.srch_id.isin(srch_ids)] for srch_ids in ids_selections ]\n",
    "selection_size, len(data_splits)\n",
    "# a = [i for i in ids_selections]\n",
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_ = sum([split.shape[0] for split in data_splits])\n",
    "assert sum_ == data.shape[0], (sum_, data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data_splits[0].index:\n",
    "    assert i not in data_splits[1].index\n",
    "\n",
    "for i in range(min(10,len(data_splits))):\n",
    "    for j in range(min(100, len(data_splits))):\n",
    "        # check index\n",
    "        if i != j:\n",
    "            for idx in data_splits[i].index:\n",
    "                assert idx not in data_splits[j].index\n",
    "\n",
    "        # check attr srch_id\n",
    "        if i != j:\n",
    "            for srch_id in data_splits[i].srch_id:\n",
    "                assert data_splits[j].query('srch_id == @srch_id').srch_id.size == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can now use (n-1) of the splits to train and the one other split to validate\n",
    "# Now we will sample from a split to prevent class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split slices again, into classes: select 1/3 booking, 1/3 click (but no booking), 1/3 none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_bookings_clicks_others(data):\n",
    "    bookings = data.query('booking_bool == 1')\n",
    "    clicks = data.query('click_bool == 1 and booking_bool != 1')\n",
    "    others = data.query('click_bool != 1')\n",
    "    \n",
    "    for i in bookings.index[:100]:\n",
    "        assert i not in clicks.index\n",
    "        assert i not in others.index\n",
    "    for i in clicks.index[:100]:\n",
    "        assert i not in bookings.index\n",
    "        assert i not in others.index\n",
    "\n",
    "    return bookings, clicks, others\n",
    "\n",
    "\n",
    "def sample(datasets=[], size_per_sample=100):\n",
    "    data = None\n",
    "    sample_indices = [ np.random.choice(data.index, size_per_sample)\n",
    "                      for data in datasets\n",
    "                     ]\n",
    "    for i in range(len(sample_indices)):\n",
    "        for j in range(len(sample_indices)):\n",
    "            if i != j: assert sample_indices[i][0] not in sample_indices[j]\n",
    "\n",
    "    # TODO should concatenation be shuffled?\n",
    "    # sklearn.utils.shuffle\n",
    "    return np.concatenate(sample_indices)\n",
    "#     return sklearn.utils.shuffle(np.concatenate(sample_indices), random_state=1234)\n",
    "#     samples = [ data.loc[np.random.choice(data.index, size_per_sample)] \n",
    "#                 for data in datasets\n",
    "#               ]\n",
    "#     ordered_dataset_samples = pd.concat(samples)\n",
    "#     return ordered_dataset_samples.sample(frac=1)\n",
    "\n",
    "def resample_bco_splits(bco_splits):\n",
    "    # Returns a list of of folds, where each fold contains indices of bookings, clicks, others\n",
    "    # :bco_splits = list of tuple of dataframes: (bookings, clicks, others)    \n",
    "    folds = []\n",
    "    for bco in bco_splits:\n",
    "        n_max = max([df.shape[0] for df in bco_split ])\n",
    "        # TODO use the average of n_max, n_min, to reduce the amount of artificial resampling?\n",
    "        fold_indices = sample(bco, n_max)\n",
    "        folds.append(fold_indices)\n",
    "\n",
    "    return folds\n",
    "\n",
    "def cv_folds(bco_splits):\n",
    "    # Return \"An iterable yielding (train, test) splits as arrays of indices\"\n",
    "    # I.e. the arg for sklearn.model_selection.cross_val_score(_, cv=arg)\n",
    "    # :bco_splits = list of tuple of dataframes: (bookings, clicks, others)    \n",
    "    folds = resample_bco_splits(bco_splits)\n",
    "    # for each step, choose (n-1) train folds and 1 test fold\n",
    "    n_folds = len(folds)\n",
    "    cv_folds = []\n",
    "    for i in range(n_folds):\n",
    "        fold_indices = np.delete(np.arange(n_folds), i)\n",
    "        # select & concatenate folds[indices]\n",
    "        indices_train = np.concatenate([ folds[j] for j in fold_indices ])\n",
    "        indices_test= folds[i]\n",
    "        cv_folds.append((indices_train, indices_test))\n",
    "\n",
    "    return cv_folds\n",
    "\n",
    "# def combine_folds(folds, indices):\n",
    "#     return np.concatenate([ folds[i][0] for i in indices ])\n",
    "    \n",
    "def split_xy(data: pd.DataFrame):\n",
    "    return data.drop(columns=y_labels).values, data['score'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [],
   "source": [
    "bco_splits = [ split_bookings_clicks_others(data) for data in data_splits ]\n",
    "\n",
    "for i in range(len(bco_splits)):\n",
    "    for j in range(len(bco_splits)):\n",
    "        if i != j:\n",
    "            for srch_id in bco_splits[i][0].srch_id:\n",
    "                assert bco_splits[j][0].query('srch_id == @srch_id').shape[0] == 0\n",
    "                assert bco_splits[j][1].query('srch_id == @srch_id').shape[0] == 0\n",
    "                assert bco_splits[j][2].query('srch_id == @srch_id').shape[0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(370, 7)"
      ]
     },
     "execution_count": 867,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# e.g. for every cv split i\n",
    "i = 0\n",
    "bco_split = bco_splits[i]\n",
    "bookings, clicks, others = bco_split\n",
    "n_max = max([xy.shape[0] for xy in bco_split ])\n",
    "n_min = min([xy.shape[0] for xy in bco_split ])\n",
    "n_max, n_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_per_sample = 2\n",
    "assert len(sample([bookings, clicks, others], size_per_sample)) == 3 * size_per_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = cv_folds(bco_splits)\n",
    "x, y = split_xy(data)\n",
    "# sklearn.model_selection.PredefinedSplit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(folds)):\n",
    "#     print(i)\n",
    "#     for j in range(len(folds)):\n",
    "#         print('\\t', j)\n",
    "#         if i != j:\n",
    "#             x = folds[i][0][0]\n",
    "#             assert folds[i][0][0] not in folds[j][0], (i,j, folds[i][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(model_func, x_train, y_train, cv_folds, k=None, results=None, v=1):\n",
    "    scores_acc = cross_val_score(model_func, x_train, y_train, cv=cv_folds, scoring='accuracy') # roc_auc accuracy\n",
    "    if results is not None:\n",
    "        results[k] = scores_acc\n",
    "    if v:\n",
    "        print('scores per fold ', scores_acc)\n",
    "        print('  mean score    ', np.mean(scores_acc))\n",
    "        print('  standard dev. ', np.std(scores_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "models = {\n",
    "#           'Logit': sklearn.linear_model.LogisticRegression(solver='liblinear',\n",
    "#                                                            multi_class='ovr'),\n",
    "# #           'SGD': sklearn.linear_model.SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=1000, tol=1e-3),\n",
    "# #           'SVC auto': sklearn.svm.SVC(gamma='auto'), \n",
    "#           'SVC': sklearn.svm.SVC(kernel='linear'), \n",
    "# #           'SVC polynomial': sklearn.svm.SVC(kernel='poly', gamma='auto', degree=4),    \n",
    "          'Decision Tree':  sklearn.tree.DecisionTreeClassifier(),\n",
    "#           'KNN 5': sklearn.neighbors.KNeighborsClassifier(n_neighbors=5),\n",
    "# #           'KNN 10': sklearn.neighbors.KNeighborsClassifier(n_neighbors=10),\n",
    "#           'Ensemble Random Forest': sklearn.ensemble.RandomForestClassifier(n_estimators=100),\n",
    "# #           'Ensemble Bagging': sklearn.ensemble.BaggingClassifier(n_estimators=100)\n",
    "#             'Gradient Boost': sklearn.ensemble.GradientBoostingRegressor(loss='ls', learning_rate=0.1, \n",
    "#                             n_estimators=100, subsample=1.0, criterion='friedman_mse', \n",
    "#                             max_depth=3,random_state=seed, alpha=0.9, tol=0.0001)    \n",
    "# #          'AdaBoost': sklearn.ensemble.AdaBoostRegressor()\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "scores per fold  [0.44954955 0.42702703 0.35135135 0.3954955  0.52072072]\n",
      "  mean score     0.4288288288288289\n",
      "  standard dev.  0.05655189683781503\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for k,m in models.items():\n",
    "    print(k)\n",
    "    cross_validation(m, x, y, folds, k, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model & Mean & Std. dev. \\\\ \n",
      "\\hline\n",
      "Decision Tree & 0.4288 & 0.0566\\\\\n",
      "\n",
      "best acc: Decision Tree 0.4288\n"
     ]
    }
   ],
   "source": [
    "# render latex table\n",
    "print('Model & Mean & Std. dev. \\\\\\\\ \\n\\\\hline')\n",
    "best_k = ''\n",
    "best_mean = 0\n",
    "for k, scores_acc in results.items():\n",
    "    if np.mean(scores_acc) > best_mean:\n",
    "        best_mean = np.mean(scores_acc)\n",
    "        best_k = k\n",
    "    print('%s & %0.4f & %0.4f\\\\\\\\' % (k, np.mean(scores_acc), np.std(scores_acc)))\n",
    "print('\\nbest acc:', best_k, round(best_mean,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1480,), (1480,), (1480,))"
      ]
     },
     "execution_count": 874,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y_train[folds[0][0]]\n",
    "y[y == 5].shape, y[y == 0].shape, y[y == 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
