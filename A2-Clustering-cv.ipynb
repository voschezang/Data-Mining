{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "import collections\n",
    "from importlib import reload\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader, Dataset, SVD, NormalPredictor\n",
    "# from surprise import evaluate\n",
    "import surprise.model_selection\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import sklearn.metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util.plot\n",
    "import util.data\n",
    "from util import clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(util.plot)\n",
    "reload(util.data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 85)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all = pd.read_csv('data/training_set_VU_DM_clean.csv', sep=';', nrows=50*1000)\n",
    "util.data.rm_na(data_all)\n",
    "data_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, data_test = util.data.train_test_split(data_all)\n",
    "\n",
    "# split cross validation folds\n",
    "folds = util.data.cv_folds_for_sklearn(data, n_cv_folds=3, resampling_ratio=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, scores: pd.DataFrame):\n",
    "    # Return a dict {user: {item: predicted score}}\n",
    "    results = collections.defaultdict(dict)\n",
    "    for _, row in scores.iterrows():\n",
    "        item = row['item']\n",
    "        user = row['user']\n",
    "        result = model.predict(str(item), str(user), verbose=0)\n",
    "        results[user][item] = result.est\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\textract_data(k: srch_id)\n",
      "\textract_data(k: prop_id)\n",
      "\tKMeans (k: `cluster_id_users_KMeans`)\n",
      "\tFeatureAgglomeration (k: `cluster_id_users_FeatureAgglomeration`)\n",
      "\tKMeans (k: `cluster_id_items_KMeans`)\n",
      "\tFeatureAgglomeration (k: `cluster_id_items_FeatureAgglomeration`)\n",
      "cluster_id_users_KMeans cluster_id_items_KMeans\n",
      "cluster_id_users_KMeans cluster_id_items_FeatureAgglomeration\n",
      "cluster_id_users_FeatureAgglomeration cluster_id_items_KMeans\n",
      "cluster_id_users_FeatureAgglomeration cluster_id_items_FeatureAgglomeration\n",
      "\textract_data(k: srch_id)\n",
      "\textract_data(k: prop_id)\n",
      "\tKMeans (k: `cluster_id_users_KMeans`)\n",
      "\tFeatureAgglomeration (k: `cluster_id_users_FeatureAgglomeration`)\n",
      "\tKMeans (k: `cluster_id_items_KMeans`)\n",
      "\tFeatureAgglomeration (k: `cluster_id_items_FeatureAgglomeration`)\n",
      "cluster_id_users_KMeans cluster_id_items_KMeans\n",
      "cluster_id_users_KMeans cluster_id_items_FeatureAgglomeration\n",
      "cluster_id_users_FeatureAgglomeration cluster_id_items_KMeans\n",
      "cluster_id_users_FeatureAgglomeration cluster_id_items_FeatureAgglomeration\n",
      "\textract_data(k: srch_id)\n",
      "\textract_data(k: prop_id)\n",
      "\tKMeans (k: `cluster_id_users_KMeans`)\n",
      "\tFeatureAgglomeration (k: `cluster_id_users_FeatureAgglomeration`)\n",
      "\tKMeans (k: `cluster_id_items_KMeans`)\n",
      "\tFeatureAgglomeration (k: `cluster_id_items_FeatureAgglomeration`)\n",
      "cluster_id_users_KMeans cluster_id_items_KMeans\n",
      "cluster_id_users_KMeans cluster_id_items_FeatureAgglomeration\n",
      "cluster_id_users_FeatureAgglomeration cluster_id_items_KMeans\n",
      "cluster_id_users_FeatureAgglomeration cluster_id_items_FeatureAgglomeration\n"
     ]
    }
   ],
   "source": [
    "# suppress warning to improve speed\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "reload(util.data)\n",
    "reload(util.clustering)\n",
    "# cluster_id_items_KMeans\n",
    "\n",
    "cv_results = collections.defaultdict(list)\n",
    "for i_train, i_test in folds:\n",
    "    # Cluser users & items\n",
    "    keys_search, keys_property, models_user, models_item = clustering.init(data_all)\n",
    "#     clustering.init_df_columns(data_all, models_user, models_item)\n",
    "    xy_train = data_all.loc[i_train]\n",
    "    clustering.fit(xy_train, models_user, keys_search,'srch_id')\n",
    "    clustering.fit(xy_train, models_item, keys_property,'prop_id')\n",
    "    \n",
    "    # predict train+test data\n",
    "    users = clustering.predict(data_all, models_user, keys_search,\n",
    "                 'srch_id', clustering.USER_KEY_PREFIX)\n",
    "    items = clustering.predict(data_all, models_item, keys_property,\n",
    "                 'prop_id', clustering.ITEM_KEY_PREFIX)\n",
    "\n",
    "    for k in users.columns:\n",
    "        util.data.replace_extremely_uncommon(users, k)\n",
    "        data_all.loc[users.index, k] = users[k]\n",
    "    for k in items.columns:\n",
    "        util.data.replace_extremely_uncommon(items, k)\n",
    "        data_all.loc[items.index, k] = items[k]\n",
    "    \n",
    "    assert not items.isna().any().any()\n",
    "    xy_train = data_all.loc[i_train]\n",
    "    xy_test = data_all.loc[i_test]\n",
    "\n",
    "    # train SVD's\n",
    "\n",
    "    # check all combinations (of all user/item models)\n",
    "    for k_user in users.columns:\n",
    "        for k_item in items.columns:\n",
    "            print(k_user, k_item)\n",
    "            assert not data_all[k_user].isna().any()\n",
    "            assert not data_all[k_item].isna().any()\n",
    "            \n",
    "            scores_train = util.data.scores_df(xy_train, k_user, k_item)\n",
    "            scores_test = util.data.scores_df(xy_test, k_user, k_item)\n",
    "\n",
    "            # check minimal occurence\n",
    "            value_counts_user = scores_train.user.value_counts(ascending=True)\n",
    "            value_counts_item = scores_train.item.value_counts(ascending=True)\n",
    "\n",
    "            scores_train_ = Dataset.load_from_df(scores_train, Reader(rating_scale=(0,5)))\n",
    "            model = SVD() # SVDpp NMF\n",
    "            trainset, _ = surprise.model_selection.train_test_split(scores_train_, test_size=0.01, random_state=seed)\n",
    "            model.fit(trainset)\n",
    "            scores_pred = clustering.svd_predict(model, scores_test)\n",
    "\n",
    "            # scores_pred\n",
    "            for i, row in xy_test.iterrows():\n",
    "                score_pred = scores_pred[row[k_user]][row[k_item]]\n",
    "                # add squared error\n",
    "                cv_results[k_user + '-' + k_item].append((score_pred - row['score'])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse\n",
      "cluster_id_users_KMeans-cluster_id_items_KMeans & 5.8631 & 7.6999\n",
      "cluster_id_users_KMeans-cluster_id_items_FeatureAgglomeration & 6.5585 & 8.9001\n",
      "cluster_id_users_FeatureAgglomeration-cluster_id_items_KMeans & 5.6798 & 7.3421\n",
      "cluster_id_users_FeatureAgglomeration-cluster_id_items_FeatureAgglomeration & 6.4911 & 8.7952\n",
      "median\n",
      "cluster_id_users_KMeans-cluster_id_items_KMeans & 0.8239 & 7.6999\n",
      "cluster_id_users_KMeans-cluster_id_items_FeatureAgglomeration & 0.3787 & 8.9001\n",
      "cluster_id_users_FeatureAgglomeration-cluster_id_items_KMeans & 1.0851 & 7.3421\n",
      "cluster_id_users_FeatureAgglomeration-cluster_id_items_FeatureAgglomeration & 0.3787 & 8.7952\n"
     ]
    }
   ],
   "source": [
    "print('mse')\n",
    "for k, values in cv_results.items():\n",
    "    print('%s & %0.4f & %0.4f' % (k,np.mean(values), np.std(values)))\n",
    "\n",
    "print('median')\n",
    "for k, values in cv_results.items():    \n",
    "    print('%s & %0.4f & %0.4f' % (k,np.median(values), np.std(values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Netflix usage of SVD: predict score for known user\n",
    "# Here: predict similarity group of user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
