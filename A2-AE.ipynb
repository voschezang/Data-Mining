{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "import collections, copy, pickle\n",
    "from termcolor import colored\n",
    "from importlib import reload\n",
    "from dateutil.parser import parse\n",
    "import scipy.linalg, scipy.stats\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'serif'\n",
    "rcParams['font.size'] = 14\n",
    "# rcParams['text.usetex'] = True\n",
    "import seaborn as sns\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "from sklearn import preprocessing\n",
    "import keras\n",
    "import keras.utils\n",
    "from keras import optimizers, backend as K\n",
    "from keras.layers import *\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util.plot\n",
    "import util.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(util.plot)\n",
    "reload(util.data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/encoder.pkl', 'rb') as f:\n",
    "#     E = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 79), 40)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/training_set_VU_DM_clean.csv', sep=';', nrows=1*1000)\n",
    "data_test = pd.read_csv('data/test_set_VU_DM.csv', sep=',', nrows=1000)\n",
    "data.shape, data.srch_id.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm  orig_destination_distance\n",
      "rm  comp1_rate\n",
      "rm  comp1_inv\n",
      "rm  comp1_rate_percent_diff\n",
      "rm  comp2_rate\n",
      "rm  comp2_inv\n",
      "rm  comp2_rate_percent_diff\n",
      "rm  comp3_rate\n",
      "rm  comp3_inv\n",
      "rm  comp3_rate_percent_diff\n",
      "rm  comp4_rate\n",
      "rm  comp4_inv\n",
      "rm  comp4_rate_percent_diff\n",
      "rm  comp5_rate\n",
      "rm  comp5_inv\n",
      "rm  comp5_rate_percent_diff\n",
      "rm  comp6_rate\n",
      "rm  comp6_inv\n",
      "rm  comp6_rate_percent_diff\n",
      "rm  comp7_rate\n",
      "rm  comp7_inv\n",
      "rm  comp7_rate_percent_diff\n",
      "rm  comp8_rate\n",
      "rm  comp8_inv\n",
      "rm  comp8_rate_percent_diff\n",
      "rm  travel_distance\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for k in data.columns:\n",
    "    if data[k].isna().sum() > 0:\n",
    "        print('rm ', k)\n",
    "        data.drop(columns=[k], inplace=True)\n",
    "\n",
    "varsUsed = list(data.columns)\n",
    "# varsUsed.remove('Unnamed')\n",
    "# varsUsed.remove('position')\n",
    "# varsUsed.remove('random_bool')\n",
    "len(varsUsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>site_id</th>\n",
       "      <th>visitor_location_country_id</th>\n",
       "      <th>visitor_hist_starrating</th>\n",
       "      <th>visitor_hist_adr_usd</th>\n",
       "      <th>prop_country_id</th>\n",
       "      <th>prop_id</th>\n",
       "      <th>prop_starrating</th>\n",
       "      <th>prop_review_score</th>\n",
       "      <th>prop_brand_bool</th>\n",
       "      <th>...</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.098734</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>893</td>\n",
       "      <td>-0.190084</td>\n",
       "      <td>-0.300346</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.098734</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10404</td>\n",
       "      <td>0.763816</td>\n",
       "      <td>0.191146</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.098734</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21315</td>\n",
       "      <td>-0.190084</td>\n",
       "      <td>0.682638</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.098734</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27348</td>\n",
       "      <td>-1.143983</td>\n",
       "      <td>0.191146</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.098734</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29604</td>\n",
       "      <td>0.763816</td>\n",
       "      <td>-0.300346</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   srch_id  site_id  visitor_location_country_id  visitor_hist_starrating  \\\n",
       "0        1      0.0                          8.0                 0.098734   \n",
       "1        1      0.0                          8.0                 0.098734   \n",
       "2        1      0.0                          8.0                 0.098734   \n",
       "3        1      0.0                          8.0                 0.098734   \n",
       "4        1      0.0                          8.0                 0.098734   \n",
       "\n",
       "   visitor_hist_adr_usd  prop_country_id  prop_id  prop_starrating  \\\n",
       "0              0.006029              0.0      893        -0.190084   \n",
       "1              0.006029              0.0    10404         0.763816   \n",
       "2              0.006029              0.0    21315        -0.190084   \n",
       "3              0.006029              0.0    27348        -1.143983   \n",
       "4              0.006029              0.0    29604         0.763816   \n",
       "\n",
       "   prop_review_score  prop_brand_bool  ...    hour  minute  Friday  Monday  \\\n",
       "0          -0.300346                1  ...       8      32       0       0   \n",
       "1           0.191146                1  ...       8      32       0       0   \n",
       "2           0.682638                1  ...       8      32       0       0   \n",
       "3           0.191146                1  ...       8      32       0       0   \n",
       "4          -0.300346                1  ...       8      32       0       0   \n",
       "\n",
       "   Saturday  Sunday  Thursday  Tuesday  Wednesday  score  \n",
       "0         0       0         1        0          0      0  \n",
       "1         0       0         1        0          0      0  \n",
       "2         0       0         1        0          0      0  \n",
       "3         0       0         1        0          0      0  \n",
       "4         0       0         1        0          0      0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AE 1) Search id\n",
    "\n",
    "See also https://blog.keras.io/building-autoencoders-in-keras.html and https://github.com/voschezang/drum-style-transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [k for k in data.columns if 'comp' not in k and 'prop' not in k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35,\n",
       " ['srch_id',\n",
       "  'site_id',\n",
       "  'visitor_location_country_id',\n",
       "  'visitor_hist_starrating',\n",
       "  'visitor_hist_adr_usd',\n",
       "  'promotion_flag',\n",
       "  'srch_destination_id',\n",
       "  'srch_length_of_stay',\n",
       "  'srch_booking_window',\n",
       "  'srch_adults_count',\n",
       "  'srch_children_count',\n",
       "  'srch_room_count',\n",
       "  'srch_saturday_night_bool',\n",
       "  'srch_query_affinity_score',\n",
       "  'visitor_hist_starrating_is_null',\n",
       "  'srch_person_per_room_score',\n",
       "  'srch_adults_per_room_score',\n",
       "  'srch_adults_count_float',\n",
       "  'srch_children_count_float',\n",
       "  'srch_room_count_float',\n",
       "  'position_float',\n",
       "  'srch_length_of_stay_float',\n",
       "  'srch_booking_window_float',\n",
       "  'year',\n",
       "  'month',\n",
       "  'day',\n",
       "  'hour',\n",
       "  'minute',\n",
       "  'Friday',\n",
       "  'Monday',\n",
       "  'Saturday',\n",
       "  'Sunday',\n",
       "  'Thursday',\n",
       "  'Tuesday',\n",
       "  'Wednesday'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rm irrelevant info\n",
    "keys_property = [k for k in data.columns if 'comp' in k or 'prop' in k]\n",
    "keys_property += ['click_bool', 'booking_bool', 'gross_bookings_usd', 'random_bool', 'score', 'price_usd', 'position', 'travel_distance', 'travel_distances']\n",
    "keys_search = [k for k in data.columns if k not in keys_property]\n",
    "len(keys_search), keys_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[keys_search]\n",
    "data.srch_id.unique()\n",
    "data_unique_srch_id = data.drop_duplicates(subset='srch_id')\n",
    "assert data_unique_srch_id.shape[0] == data.srch_id.unique().size, \\\n",
    "    'if srch_id is equal, all non-property attributes should be equal as well'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert data_unique_srch_id.srch_id.min() > 0, 'search id must be positive and nonzero'\n",
    "assert ~data_unique_srch_id.srch_id.isna().any()\n",
    "assert ~data_unique_srch_id.isna().any().any()\n",
    "assert ~data_unique_srch_id.isin([np.nan, np.inf, -np.inf]).any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40, 1), (40, 40), (40, 35, 1))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to np array & reshape\n",
    "sample = data_unique_srch_id.sample(frac=1, random_state=seed)\n",
    "x_train = sample.values[:,:,np.newaxis]\n",
    "# x_train = data_unique_srch_id.values\n",
    "# x_train = x_train.reshape(x_train.shape + (1,))\n",
    "y_labels = x_train[:,0,:]\n",
    "discretizer = preprocessing.KBinsDiscretizer(n_bins=y_labels.shape[0],\n",
    "         encode='onehot', strategy='uniform')\n",
    "y_train = discretizer.fit_transform(y_labels)\n",
    "y_labels.shape, y_train.shape, x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ~np.any(np.isinf(x_train))\n",
    "assert ~np.any(np.isinf(-x_train))\n",
    "assert ~np.any(np.isnan(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.toarray()\n",
    "y_train = y_train[:,:,np.newaxis]\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.random.random(x_train.shape)\n",
    "y_train = np.random.random(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 1) (40, 1)\n"
     ]
    }
   ],
   "source": [
    "# n_dims = data.shape[1]\n",
    "input_shape = x_train.shape[1:]\n",
    "output_shape = y_train.shape[1:]\n",
    "print(input_shape, output_shape)\n",
    "encoder_input = Input(shape=input_shape)\n",
    "h = encoder_input\n",
    "h = Flatten()(h)\n",
    "h = Dense(100, activation='relu')(h)\n",
    "# decoder\n",
    "h = Dense(np.prod(output_shape), activation='relu')(h)\n",
    "h = Reshape(output_shape)(h)\n",
    "encoder_output = Activation('sigmoid')(h)\n",
    "model = Model(encoder_input, encoder_output, name='ae-')\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy') # RMSprop Adadelta SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32 samples, validate on 8 samples\n",
      "Epoch 1/2\n",
      "32/32 [==============================] - 1s 23ms/step - loss: 0.6963 - val_loss: 0.7009\n",
      "Epoch 2/2\n",
      "32/32 [==============================] - 0s 232us/step - loss: 0.6938 - val_loss: 0.6991\n"
     ]
    }
   ],
   "source": [
    "# validation_split does not shuffle the data\n",
    "result = model.fit(x_train, y_train, epochs=2, batch_size=int(x_train.shape[0]/2), validation_split=0.2)\n",
    "# history = result.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': [0.7009005546569824, 0.6990842819213867],\n",
       " 'loss': [0.6962836757302284, 0.6937669888138771]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result.params\n",
    "result.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.5       ],\n",
       "        [0.5331072 ],\n",
       "        [0.5       ],\n",
       "        ...,\n",
       "        [0.5       ],\n",
       "        [0.5       ],\n",
       "        [0.5       ]],\n",
       "\n",
       "       [[0.5       ],\n",
       "        [0.5099149 ],\n",
       "        [0.5       ],\n",
       "        ...,\n",
       "        [0.5       ],\n",
       "        [0.5       ],\n",
       "        [0.5       ]],\n",
       "\n",
       "       [[0.5       ],\n",
       "        [0.53613913],\n",
       "        [0.5       ],\n",
       "        ...,\n",
       "        [0.5       ],\n",
       "        [0.5       ],\n",
       "        [0.5       ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.5       ],\n",
       "        [0.5262796 ],\n",
       "        [0.5       ],\n",
       "        ...,\n",
       "        [0.5       ],\n",
       "        [0.5       ],\n",
       "        [0.5       ]],\n",
       "\n",
       "       [[0.5       ],\n",
       "        [0.51714003],\n",
       "        [0.5       ],\n",
       "        ...,\n",
       "        [0.5       ],\n",
       "        [0.5       ],\n",
       "        [0.5       ]],\n",
       "\n",
       "       [[0.5       ],\n",
       "        [0.537264  ],\n",
       "        [0.5       ],\n",
       "        ...,\n",
       "        [0.5       ],\n",
       "        [0.5500683 ],\n",
       "        [0.5389925 ]]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_encoder(input_shape=(10,1), latent_dim=2):\n",
    "    encoder_input = Input(shape=input_shape)\n",
    "    n_nodes = np.prod(input_shape)\n",
    "\n",
    "    # Convolution\n",
    "    h = encoder_input\n",
    "    h = Reshape((timesteps, notes))(h)\n",
    "    h = Conv1D(\n",
    "        64, kernel_size=2, strides=1, activation='relu', padding='valid')(h)\n",
    "\n",
    "    h = Bidirectional(LSTM(128))(h)\n",
    "\n",
    "    # Z Mean, Variance\n",
    "    z_mean = Dense(latent_dim, name='z_mean')(h)  # no activation='relu'\n",
    "    z_log_var = Dense(latent_dim, name='z_log_var')(h)  # no activation='relu'\n",
    "\n",
    "    encoder_output = [z_mean, z_log_var]\n",
    "    encoder_model = Model(encoder_input, encoder_output, name='encoder_model-')\n",
    "    return encoder_model, encoder_input, z_mean, z_log_var\n",
    "\n",
    "\n",
    "def init(input_shape=(36, 1), latent_dim=10, epsilon_std=1.):\n",
    "    encoder_model, encoder_input, z_mean, z_log_var = encoder(\n",
    "        input_shape, latent_dim)\n",
    "    z_input = encoder_model(encoder_input)\n",
    "\n",
    "    # this function must be defined locally in order for the model to be serializable\n",
    "    # using the following inline lambda function will result in an error when .to_json() is called\n",
    "    #   lambda args: sample(args, z_mean, z_log_var, latent_dim, epsilon_std)\n",
    "    def sample(args):\n",
    "        z_mean, z_log_var = args\n",
    "        epsilon = K.random_normal(\n",
    "            shape=(K.shape(z_mean)[0], latent_dim),\n",
    "            mean=0.,\n",
    "            stddev=epsilon_std)\n",
    "        return z_mean + K.exp(z_log_var) * epsilon\n",
    "\n",
    "    z_output = Lambda(sample)(z_input)\n",
    "    decoder_model = decoder(z_output, latent_dim, input_shape)\n",
    "\n",
    "    # VAE\n",
    "    vae_input = Input(shape=(input_shape, ))\n",
    "    vae_input = encoder_input\n",
    "    vae_output = decoder_model(z_output)\n",
    "    # vae_output = decoder_model(z_mean)\n",
    "    vae = Model(vae_input, vae_output, name='vae-model-')\n",
    "\n",
    "    vae_loss_ = vae_loss(\n",
    "        vae_input,\n",
    "        vae_output,\n",
    "        z_mean,\n",
    "        z_log_var,\n",
    "        timesteps,\n",
    "        notes,\n",
    "        beta=0.75,\n",
    "        gamma=0.05)\n",
    "    vae.add_loss(vae_loss_)\n",
    "    vae.compile(optimizer='adam')\n",
    "\n",
    "    # Encoder (matrices -> latent vectors)\n",
    "    encoder_ = Model(encoder_input, z_mean)\n",
    "    # Generator (latent vectors -> matrices)\n",
    "    # generator_input = Input((latent_dim, ))\n",
    "    # generator_layers_ = utils.composition(decoders, generator_input)\n",
    "    # generator = Model(generator_input, generator_layers_)\n",
    "    return vae, encoder_, decoder_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/visualising-high-dimensional-datasets-using-pca-and-t-sne-in-python-8ef87e7915b\n",
    "    \n",
    "<img src=\"https://cdn-images-1.medium.com/max/1200/1*BrwllztzxZO89qCB9w5d-w.png\" style=\"width:50%;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
