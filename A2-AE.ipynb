{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "import collections, copy, pickle\n",
    "from termcolor import colored\n",
    "from importlib import reload\n",
    "from dateutil.parser import parse\n",
    "import scipy.linalg, scipy.stats\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'serif'\n",
    "rcParams['font.size'] = 14\n",
    "# rcParams['text.usetex'] = True\n",
    "import seaborn as sns\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "from sklearn import preprocessing\n",
    "import keras\n",
    "import keras.utils\n",
    "from keras import optimizers, backend as K\n",
    "from keras.layers import *\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util.plot\n",
    "import util.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(util.plot)\n",
    "reload(util.data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/encoder.pkl', 'rb') as f:\n",
    "#     E = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 79), 40)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/training_set_VU_DM_clean.csv', sep=';', nrows=1*1000)\n",
    "data_test = pd.read_csv('data/test_set_VU_DM.csv', sep=',', nrows=1000)\n",
    "data.shape, data.srch_id.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srch_id</th>\n",
       "      <th>site_id</th>\n",
       "      <th>visitor_location_country_id</th>\n",
       "      <th>visitor_hist_starrating</th>\n",
       "      <th>visitor_hist_adr_usd</th>\n",
       "      <th>prop_country_id</th>\n",
       "      <th>prop_id</th>\n",
       "      <th>prop_starrating</th>\n",
       "      <th>prop_review_score</th>\n",
       "      <th>prop_brand_bool</th>\n",
       "      <th>...</th>\n",
       "      <th>minute</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>Wednesday</th>\n",
       "      <th>score</th>\n",
       "      <th>travel_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.098734</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>893</td>\n",
       "      <td>-0.190084</td>\n",
       "      <td>-0.300346</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.098734</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10404</td>\n",
       "      <td>0.763816</td>\n",
       "      <td>0.191146</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.098734</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21315</td>\n",
       "      <td>-0.190084</td>\n",
       "      <td>0.682638</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.098734</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27348</td>\n",
       "      <td>-1.143983</td>\n",
       "      <td>0.191146</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.098734</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29604</td>\n",
       "      <td>0.763816</td>\n",
       "      <td>-0.300346</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   srch_id  site_id  visitor_location_country_id  visitor_hist_starrating  \\\n",
       "0        1      0.0                          8.0                 0.098734   \n",
       "1        1      0.0                          8.0                 0.098734   \n",
       "2        1      0.0                          8.0                 0.098734   \n",
       "3        1      0.0                          8.0                 0.098734   \n",
       "4        1      0.0                          8.0                 0.098734   \n",
       "\n",
       "   visitor_hist_adr_usd  prop_country_id  prop_id  prop_starrating  \\\n",
       "0              0.006029              0.0      893        -0.190084   \n",
       "1              0.006029              0.0    10404         0.763816   \n",
       "2              0.006029              0.0    21315        -0.190084   \n",
       "3              0.006029              0.0    27348        -1.143983   \n",
       "4              0.006029              0.0    29604         0.763816   \n",
       "\n",
       "   prop_review_score  prop_brand_bool       ...         minute  Friday  \\\n",
       "0          -0.300346                1       ...             32       0   \n",
       "1           0.191146                1       ...             32       0   \n",
       "2           0.682638                1       ...             32       0   \n",
       "3           0.191146                1       ...             32       0   \n",
       "4          -0.300346                1       ...             32       0   \n",
       "\n",
       "   Monday  Saturday  Sunday  Thursday  Tuesday  Wednesday  score  \\\n",
       "0       0         0       0         1        0          0      0   \n",
       "1       0         0       0         1        0          0      0   \n",
       "2       0         0       0         1        0          0      0   \n",
       "3       0         0       0         1        0          0      0   \n",
       "4       0         0       0         1        0          0      0   \n",
       "\n",
       "   travel_distance  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4              NaN  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AE 1) Search id\n",
    "\n",
    "See also https://blog.keras.io/building-autoencoders-in-keras.html and https://github.com/voschezang/drum-style-transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [k for k in data.columns if 'comp' not in k and 'prop' not in k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36,\n",
       " ['srch_id',\n",
       "  'site_id',\n",
       "  'visitor_location_country_id',\n",
       "  'visitor_hist_starrating',\n",
       "  'visitor_hist_adr_usd',\n",
       "  'promotion_flag',\n",
       "  'srch_destination_id',\n",
       "  'srch_length_of_stay',\n",
       "  'srch_booking_window',\n",
       "  'srch_adults_count',\n",
       "  'srch_children_count',\n",
       "  'srch_room_count',\n",
       "  'srch_saturday_night_bool',\n",
       "  'srch_query_affinity_score',\n",
       "  'orig_destination_distance',\n",
       "  'visitor_hist_starrating_is_null',\n",
       "  'srch_person_per_room_score',\n",
       "  'srch_adults_per_room_score',\n",
       "  'srch_adults_count_float',\n",
       "  'srch_children_count_float',\n",
       "  'srch_room_count_float',\n",
       "  'position_float',\n",
       "  'srch_length_of_stay_float',\n",
       "  'srch_booking_window_float',\n",
       "  'year',\n",
       "  'month',\n",
       "  'day',\n",
       "  'hour',\n",
       "  'minute',\n",
       "  'Friday',\n",
       "  'Monday',\n",
       "  'Saturday',\n",
       "  'Sunday',\n",
       "  'Thursday',\n",
       "  'Tuesday',\n",
       "  'Wednesday'])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rm irrelevant info\n",
    "keys_property = [k for k in data.columns if 'comp' in k or 'prop' in k]\n",
    "keys_property += ['click_bool', 'booking_bool', 'gross_bookings_usd', 'random_bool', 'score', 'price_usd', 'position', 'travel_distance', 'travel_distances']\n",
    "keys_search = [k for k in data.columns if k not in keys_property]\n",
    "len(keys_search), keys_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[keys_search]\n",
    "data.srch_id.unique()\n",
    "data_unique_srch_id = data.drop_duplicates(subset='srch_id')\n",
    "assert data_unique_srch_id.shape[0] == data.srch_id.unique().size, \\\n",
    "    'if srch_id is equal, all non-property attributes should be equal as well'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert data.srch_id.isna().sum() == 0\n",
    "assert data.srch_id.isin([np.nan, np.inf, -np.inf]).sum() == 0\n",
    "assert data.srch_id.min() > 0\n",
    "# assert data.srch_id.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40, 1), (40, 40))"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to np array & reshape\n",
    "data = data.sample(frac=1, random_state=seed)\n",
    "x_train = data_unique_srch_id.values[:,:,np.newaxis]\n",
    "y_labels = x_train[:,0,:]\n",
    "discretizer = preprocessing.KBinsDiscretizer(n_bins=y_labels.shape[0],\n",
    "         encode='onehot', strategy='uniform')\n",
    "y_train = discretizer.fit_transform(y_labels)\n",
    "y_labels.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 1)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train.toarray()\n",
    "y_train = y_train[:,:,np.newaxis]\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 1) (40, 1)\n"
     ]
    }
   ],
   "source": [
    "# n_dims = data.shape[1]\n",
    "input_shape = x_train.shape[1:]\n",
    "output_shape = y_train.shape[1:]\n",
    "print(input_shape, output_shape)\n",
    "encoder_input = Input(shape=input_shape)\n",
    "h = encoder_input\n",
    "h = Flatten()(h)\n",
    "h = Dense(100, activation='relu')(h)\n",
    "# decoder\n",
    "h = Dense(np.prod(output_shape), activation='relu')(h)\n",
    "h = Reshape(output_shape)(h)\n",
    "encoder_output = Activation('sigmoid')(h)\n",
    "model = Model(encoder_input, encoder_output, name='ae-')\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy') # RMSprop Adadelta SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32 samples, validate on 8 samples\n",
      "Epoch 1/2\n",
      "32/32 [==============================] - 1s 34ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/2\n",
      "32/32 [==============================] - 0s 224us/step - loss: nan - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "# validation_split does not shuffle the data\n",
    "result = model.fit(x_train, y_train, epochs=2, batch_size=int(x_train.shape[0]/2), validation_split=0.2)\n",
    "# history = result.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [nan, nan]}"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result.params\n",
    "result.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        ...,\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan]],\n",
       "\n",
       "       [[1. ],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        ...,\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ]],\n",
       "\n",
       "       [[1. ],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        ...,\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1. ],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        ...,\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ]],\n",
       "\n",
       "       [[1. ],\n",
       "        [0.5],\n",
       "        [0.5],\n",
       "        ...,\n",
       "        [1. ],\n",
       "        [1. ],\n",
       "        [1. ]],\n",
       "\n",
       "       [[nan],\n",
       "        [nan],\n",
       "        [nan],\n",
       "        ...,\n",
       "        [nan],\n",
       "        [nan],\n",
       "        [nan]]], dtype=float32)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_encoder(input_shape=(10,1), latent_dim=2):\n",
    "    encoder_input = Input(shape=input_shape)\n",
    "    n_nodes = np.prod(input_shape)\n",
    "\n",
    "    # Convolution\n",
    "    h = encoder_input\n",
    "    h = Reshape((timesteps, notes))(h)\n",
    "    h = Conv1D(\n",
    "        64, kernel_size=2, strides=1, activation='relu', padding='valid')(h)\n",
    "\n",
    "    h = Bidirectional(LSTM(128))(h)\n",
    "\n",
    "    # Z Mean, Variance\n",
    "    z_mean = Dense(latent_dim, name='z_mean')(h)  # no activation='relu'\n",
    "    z_log_var = Dense(latent_dim, name='z_log_var')(h)  # no activation='relu'\n",
    "\n",
    "    encoder_output = [z_mean, z_log_var]\n",
    "    encoder_model = Model(encoder_input, encoder_output, name='encoder_model-')\n",
    "    return encoder_model, encoder_input, z_mean, z_log_var\n",
    "\n",
    "\n",
    "def init(input_shape=(36, 1), latent_dim=10, epsilon_std=1.):\n",
    "    encoder_model, encoder_input, z_mean, z_log_var = encoder(\n",
    "        input_shape, latent_dim)\n",
    "    z_input = encoder_model(encoder_input)\n",
    "\n",
    "    # this function must be defined locally in order for the model to be serializable\n",
    "    # using the following inline lambda function will result in an error when .to_json() is called\n",
    "    #   lambda args: sample(args, z_mean, z_log_var, latent_dim, epsilon_std)\n",
    "    def sample(args):\n",
    "        z_mean, z_log_var = args\n",
    "        epsilon = K.random_normal(\n",
    "            shape=(K.shape(z_mean)[0], latent_dim),\n",
    "            mean=0.,\n",
    "            stddev=epsilon_std)\n",
    "        return z_mean + K.exp(z_log_var) * epsilon\n",
    "\n",
    "    z_output = Lambda(sample)(z_input)\n",
    "    decoder_model = decoder(z_output, latent_dim, input_shape)\n",
    "\n",
    "    # VAE\n",
    "    vae_input = Input(shape=(input_shape, ))\n",
    "    vae_input = encoder_input\n",
    "    vae_output = decoder_model(z_output)\n",
    "    # vae_output = decoder_model(z_mean)\n",
    "    vae = Model(vae_input, vae_output, name='vae-model-')\n",
    "\n",
    "    vae_loss_ = vae_loss(\n",
    "        vae_input,\n",
    "        vae_output,\n",
    "        z_mean,\n",
    "        z_log_var,\n",
    "        timesteps,\n",
    "        notes,\n",
    "        beta=0.75,\n",
    "        gamma=0.05)\n",
    "    vae.add_loss(vae_loss_)\n",
    "    vae.compile(optimizer='adam')\n",
    "\n",
    "    # Encoder (matrices -> latent vectors)\n",
    "    encoder_ = Model(encoder_input, z_mean)\n",
    "    # Generator (latent vectors -> matrices)\n",
    "    # generator_input = Input((latent_dim, ))\n",
    "    # generator_layers_ = utils.composition(decoders, generator_input)\n",
    "    # generator = Model(generator_input, generator_layers_)\n",
    "    return vae, encoder_, decoder_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
